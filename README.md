# Holographic_Reality_Navigation
National Key R&D Plan "Intelligent Robot" Special Project: Magnetic Resonance Compatible Surgical Robot for Brain Nerve Intervention
1. Independently developed a surgical interactive assistance system based on Unity 3D, which has been deployed at the United Hospital and has participated in the 7th World Intelligent Congress.
2. Through geometric calculations for surgical path planning, Pyramid Vision Transformer is combined with a CNN network model to perform lesion semantic segmentation and localization on preoperative images of patients, generating a three-dimensional "knowledge-based" virtual surgical knowledge model.
3. Utilize external plugins such as Ultraleaf, OpenHaptics, and MRTK in Unity to develop system functionality with tactile interactive devices, and deploy the project on HoloLens and PC.
4. Realize the registration display of medical models, gesture recognition, and force feedback interaction, achieving the purpose of preoperative exercises and intraoperative guidance.

"HoloLens view.mp4" and "Holographic Reality Navigation effect.mp4", these two videos demonstrate the working effect of this system. The hardware devices applied are: LeapMotion stereoscopic camera, Geomagic Touch triaxial force feedback device, holographic projector, and augmented reality glasses Hololens. Through LeapMotion, gesture recognition interactive operations for virtual human bodies have been achieved, such as moving, scaling, resetting, rotating, highlighting key tissues and organs, etc. Control the virtual bone drill through Geomagic Touch and provide contact force feedback when the virtual bone drill comes into contact with the virtual human body. HoloLens enables the display and registration of surgical knowledge models. If you have the above devices and would like to experience the functionality of the system or are interested in this project, please contact me via email: chenjr@nankai.edu.cn
